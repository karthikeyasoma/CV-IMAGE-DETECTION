{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from flask import Flask, render_template, Response\r\n",
    "import cv2\r\n",
    "import face_recognition\r\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "app = Flask(__name__)\r\n",
    "camera = cv2.VideoCapture(0)\r\n",
    "\r\n",
    "\r\n",
    "Rohit_image = face_recognition.load_image_file(\"Rohit/Rohit.jpg\")\r\n",
    "Rohit_face_encoding = face_recognition.face_encodings(Rohit_image)[0]\r\n",
    "\r\n",
    "Kohli_image = face_recognition.load_image_file(\"Kohli/Kohli.jpeg\")\r\n",
    "Kohli_face_encoding = face_recognition.face_encodings(Kohli_image)[0]\r\n",
    "\r\n",
    "known_face_encodings = [\r\n",
    "    Rohit_face_encoding,\r\n",
    "    Kohli_face_encoding\r\n",
    "]\r\n",
    "\r\n",
    "known_face_names = [\r\n",
    "    \"Rohit\",\r\n",
    "    \"Kohli\"\r\n",
    "]\r\n",
    "face_locations = []\r\n",
    "face_encodings = []\r\n",
    "face_names = []\r\n",
    "def generate_frames():  \r\n",
    "    while True:\r\n",
    "        success, frame = camera.read() \r\n",
    "        if not success:\r\n",
    "            break\r\n",
    "        else:\r\n",
    "            small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\r\n",
    "            rgb_small_frame = small_frame[:, :, ::-1]           \r\n",
    "            face_locations = face_recognition.face_locations(rgb_small_frame)\r\n",
    "            face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)\r\n",
    "            face_names = []\r\n",
    "            for face_encoding in face_encodings:\r\n",
    "                # Compare a list of face encodings against a candidate encoding to see if they match.\r\n",
    "                matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\r\n",
    "                name = \"Unknown\"\r\n",
    "                 # Given a list of face encodings, compare them to a known face encoding and get a euclidean distance for each comparison face. \r\n",
    "                # The distance tells you how similar the faces are.\r\n",
    "                face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\r\n",
    "                # Returns the indices of the minimum values along an axis.\r\n",
    "                best_match_index = np.argmin(face_distances)\r\n",
    "                if matches[best_match_index]:\r\n",
    "                    name = known_face_names[best_match_index]\r\n",
    "                face_names.append(name)\r\n",
    "            \r\n",
    "\r\n",
    "            for (top, right, bottom, left), name in zip(face_locations, face_names):\r\n",
    "                top *= 4\r\n",
    "                right *= 4\r\n",
    "                bottom *= 4\r\n",
    "                left *= 4\r\n",
    "\r\n",
    "                cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\r\n",
    "\r\n",
    "                cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 0, 255), cv2.FILLED)\r\n",
    "                font = cv2.FONT_HERSHEY_DUPLEX\r\n",
    "                cv2.putText(frame, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\r\n",
    "\r\n",
    "            ret, buffer = cv2.imencode('.jpg', frame)\r\n",
    "            frame = buffer.tobytes()\r\n",
    "            yield (b'--frame\\r\\n'\r\n",
    "                   b'Content-Type: image/jpeg\\r\\n\\r\\n' + frame + b'\\r\\n')\r\n",
    "\r\n",
    "\r\n",
    "@app.route('/')\r\n",
    "def Display():\r\n",
    "    return render_template('Display.html')\r\n",
    "@app.route('/video_feed')\r\n",
    "def video_feed():\r\n",
    "    return Response(generate_frames(), mimetype='multipart/x-mixed-replace; boundary=frame')\r\n",
    "app.run()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " * Serving Flask app '__main__' (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [06/Sep/2021 15:27:37] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Sep/2021 15:27:38] \"GET /video_feed HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.13 64-bit (system)"
  },
  "interpreter": {
   "hash": "97c4470e9141f1930a7fcc3e1f93b1ccb194bbdbd60930e83b246caa3a7eb598"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}